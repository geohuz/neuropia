基于配置模板继承系统，这里是一个完整的实现方案，让用户可以灵活指定或使用默认的 provider/model。

## 完整实现示例

### 1. 多层配置继承结构

#### 平台级配置（org-default-config）
```json
{
  "strategy": { "mode": "conditional" },
  "retry": { "attempts": 3 },
  "cache": { "mode": "simple", "maxAge": 300 },
  "defaultInputGuardrails": [
    {
      "id": "org-security",
      "type": "guardrail",
      "deny": true,
      "checks": [{"id": "default.jwt", "parameters": {...}}]
    }
  ]
}
```

#### 团队模板（engineering-team-template）
```json
{
  "extends": "org-default-config",
  "targets": [
    {
      "name": "dashscope-target",
      "provider": "dashscope",
      "override_params": {"model": "qwen-turbo"}
    },
    {
      "name": "openai-target",
      "provider": "openai", 
      "override_params": {"model": "gpt-4"}
    },
    {
      "name": "anthropic-target",
      "provider": "anthropic",
      "override_params": {"model": "claude-3-sonnet"}
    }
  ],
  "defaultInputGuardrails": [
    {
      "id": "team-models",
      "type": "guardrail",
      "deny": true,
      "checks": [{
        "id": "default.modelWhitelist",
        "parameters": {
          "models": ["qwen-turbo", "gpt-4", "claude-3-sonnet"],
          "not": false
        }
      }]
    }
  ]
}
```

#### 用户个人配置
```json
{
  "extends": "engineering-team-template",
  "strategy": {
    "mode": "conditional",
    "conditions": [
      {
        "query": {"metadata.selected_provider": "dashscope"},
        "then": "dashscope-target"
      },
      {
        "query": {"metadata.selected_provider": "openai"},
        "then": "openai-target"
      },
      {
        "query": {"metadata.selected_provider": "anthropic"},
        "then": "anthropic-target"
      }
    ],
    "default": "dashscope-target"
  }
}
```

### 2. 用户请求方式

#### 使用默认配置（不指定）
```bash
curl -X POST http://localhost:3001/v1/chat/completions \
  -H "Authorization: Bearer vk_xxx" \
  -H "x-portkey-config: [用户个人配置ID]" \
  -d '{
    "model": "any-model",
    "messages": [{"role": "user", "content": "Hello"}]
  }'
```
系统使用默认的 `dashscope-target`，model 会被 `override_params` 覆盖为 `qwen-turbo`。

#### 指定特定 provider
```bash
# 选择 OpenAI
curl -X POST http://localhost:3001/v1/chat/completions \
  -H "Authorization: Bearer vk_xxx" \
  -H "x-portkey-config: [用户个人配置ID]" \
  -H "x-portkey-metadata: {\"selected_provider\":\"openai\"}" \
  -d '{
    "model": "any-model",
    "messages": [{"role": "user", "content": "Hello"}]
  }'

# 选择 Anthropic
curl -X POST http://localhost:3001/v1/chat/completions \
  -H "Authorization: Bearer vk_xxx" \
  -H "x-portkey-config: [用户个人配置ID]" \
  -H "x-portkey-metadata: {\"selected_provider\":\"anthropic\"}" \
  -d '{
    "model": "any-model", 
    "messages": [{"role": "user", "content": "Hello"}]
  }'
```

### 3. 配置处理流程

系统通过 `constructConfigFromRequestHeaders` 自动处理： [1](#22-0) 

1. **加载配置**：读取用户个人配置
2. **解析继承**：递归加载父配置（团队模板→平台配置） [2](#22-1) 
3. **合并配置**：深度合并所有配置项
4. **条件路由**：根据 metadata 选择 target [3](#22-2) 
5. **参数覆盖**：应用 `override_params` [4](#22-3) 

### 4. 配置继承规则

| 配置项            | 继承行为               | 示例                        |
| ----------------- | ---------------------- | --------------------------- |
| `override_params` | 深度合并，子覆盖父     | model 从 qwen-turbo → gpt-4 |
| `retry`           | 子配置完全覆盖父配置   | 团队重试设置覆盖平台设置    |
| `guardrails`      | 数组连接，所有规则生效 | 平台JWT + 团队模型白名单    |
| `cache`           | 子配置覆盖父配置       | 团队缓存设置覆盖平台设置    |

## Notes

- 配置继承是 Portkey 原生支持，无需额外代码处理 [5](#22-4) 
- 条件路由让用户在预配置范围内自由选择
- 默认回退确保即使不指定也能正常工作
- 所有配置验证自动生效，确保安全性 [6](#22-5) 

这种设计让你能够灵活管理多层级配置，同时给用户最终的选择权。

# 控制用户可用范围, 同时允许指定

```json
{
  "default": "dashscope",
  "targets": [
    {
      "name": "openai",
      "provider": "openai"
    },
    {
      "name": "anthropic",
      "provider": "anthropic"
    },
    {
      "name": "dashscope",
      "provider": "dashscope"
    }
  ],
  "strategy": {
    "mode": "conditional",
    "conditions": [
      {
        "then": "openai",
        "query": {
          "params.model": {
            "$in": [
              "gpt-4",
              "gpt-3.5-turbo"
            ]
          }
        }
      },
      {
        "then": "anthropic",
        "query": {
          "params.model": "claude-3-haiku-20240307"
        }
      },
      {
        "then": "dashscope",
        "query": {
          "params.model": "qwen-turbo"
        }
      }
    ]
  },
  "before_request_hooks": [
    {
      "id": "model-whitelist",
      "deny": false,
      "type": "guardrail",
      "checks": [
        {
          "id": "default.modelWhitelist",
          "parameters": {
            "models": [
              "gpt-4",
              "gpt-3.5-turbo",
              "claude-3-haiku-20240307",
              "qwen-turbo"
            ]
          }
        }
      ]
    }
  ]
}
```

```
curl -X POST http://localhost:3001/v1/chat/completions \
  -H "Authorization: Bearer vk_908782e38b24598fb24da818eea36ef2" \
  -H "Content-Type: application/json" \
  -d '{

    "model": "qwen-turbo",
    "messages": [
      {"role": "user", "content": "Hello, please respond with TEST_SUCCESS"}
    ]
  }'
  
  {"choices":[{"message":{"role":"assistant","content":"TEST_SUCCESS"},"finish_reason":"stop","index":0,"logprobs":null}],"object":"chat.completion","usage":{"prompt_tokens":19,"completion_tokens":2,"total_tokens":21,"prompt_tokens_details":{"cached_tokens":0}},"created":1765126349,"system_fingerprint":null,"model":"qwen-turbo","id":"chatcmpl-5b573377-ba62-455d-82ae-fa333aadc551","provider":"dashscope","hook_results":{"before_request_hooks":[{"verdict":true,"id":"model-whitelist","transformed":false,"checks":[{"data":{"verdict":true,"not":false,"explanation":"Model \"qwen-turbo\" is allowed.","requestedModel":"qwen-turbo","allowedModels":["gpt-4","gpt-3.5-turbo","claude-3-haiku-20240307","qwen-turbo"]},"verdict":true,"id":"default.modelWhitelist","execution_time":0,"transformed":false,"created_at":"2025-12-07T16:52:28.217Z","log":null,"fail_on_error":false}],"feedback":null,"execution_time":0,"async":false,"type":"guardrail","created_at":"2025-12-07T16:52:28.217Z","deny":false}],"after_request_hooks":[]},"billing":{"charged":{"cost":0.147,"new_balance":68.2153}}}%    
```

```
curl -X POST http://localhost:3001/v1/chat/completions \
  -H "Authorization: Bearer vk_908782e38b24598fb24da818eea36ef2" \
  -H "Content-Type: application/json" \
  -d '{

    "model": "gpt-4",
    "messages": [
      {"role": "user", "content": "Hello, please respond with TEST_SUCCESS"}
    ]
  }'
{"error":"内部服务器错误","code":"INTERNAL_ERROR","request_id":"req_1765127410837_iff61dtyo","details":"Portkey Gateway error: 401 Unauthorized"}%                                               
```

